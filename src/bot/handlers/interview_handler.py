# src/bot/handlers/interview_handler.py

from aiogram import Router, types
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.filters import Command

from src.bot.ai.llm_router import route  # LLaMA

router = Router()


# ===============================================================
#  FSM —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é
# ===============================================================

class InterviewState(StatesGroup):
    waiting_for_topic = State()
    asking_question = State()
    waiting_for_answer = State()


# ===============================================================
#  /interview ‚Äî –∑–∞–ø—É—Å–∫
# ===============================================================

@router.message(Command("interview"))
async def start_interview(message: types.Message, state: FSMContext):
    """
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é.
    """
    await state.set_state(InterviewState.waiting_for_topic)
    await message.answer(
        "üìù –û —á—ë–º –ø—Ä–æ–≤–µ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä–≤—å—é?\n\n"
        "–ù–∞–ø—Ä–∏–º–µ—Ä: `Python`, `DevOps`, `LLM`, `–ò–ë`.",
        parse_mode="Markdown"
    )


# ===============================================================
#  –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–º—ã –∏–Ω—Ç–µ—Ä–≤—å—é
# ===============================================================

@router.message(InterviewState.waiting_for_topic)
async def set_topic(message: types.Message, state: FSMContext):
    topic = message.text.strip()

    await state.update_data(topic=topic)

    await message.answer(f"üëç –¢–µ–º–∞ –∏–Ω—Ç–µ—Ä–≤—å—é —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: **{topic}**", parse_mode="Markdown")

    # –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å
    question = await route(f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –æ–¥–∏–Ω —Å–ª–æ–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ '{topic}'.")
    await state.update_data(last_question=question)

    await state.set_state(InterviewState.waiting_for_answer)
    await message.answer(f"‚ùì {question}")


# ===============================================================
#  –û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ‚Üí —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å
# ===============================================================

@router.message(InterviewState.waiting_for_answer)
async def process_answer(message: types.Message, state: FSMContext):
    data = await state.get_data()
    topic = data.get("topic")
    user_answer = message.text

    # –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLaMA
    evaluation = await route(
        f"–í–æ–ø—Ä–æ—Å: {data['last_question']}\n"
        f"–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_answer}\n\n"
        f"–û—Ü–µ–Ω–∏ –æ—Ç–≤–µ—Ç –ø–æ —à–∫–∞–ª–µ 1‚Äì5 –∏ –∫—Ä–∞—Ç–∫–æ –æ–±–æ—Å–Ω—É–π."
    )

    await message.answer(f"üìä *–û—Ü–µ–Ω–∫–∞:*\n{evaluation}", parse_mode="Markdown")

    # –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å
    next_q = await route(f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –µ—â—ë –æ–¥–∏–Ω —Ö–æ—Ä–æ—à–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ '{topic}'.")
    await state.update_data(last_question=next_q)

    await message.answer(f"‚ùì {next_q}")


# ===============================================================
#  /interviewstop ‚Äî –¥–ª—è –≤—ã—Ö–æ–¥–∞
# ===============================================================

@router.message(Command("interviewstop"))
async def stop_interview(message: types.Message, state: FSMContext):
    await state.clear()
    await message.answer("üõë –ò–Ω—Ç–µ—Ä–≤—å—é –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")
